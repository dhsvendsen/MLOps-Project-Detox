import wandb
import numpy as np
import random

import yaml

# Load sweep config from YAML file
with open("train_config.yaml", "r") as f:
    sweep_configuration = yaml.load(f, Loader=yaml.FullLoader)

# No need to redefine the sweep configuration in here unless we want it repeated for clarity?
"""
sweep_configuration = {
    "method": config_yaml["method"],
    "name": config_yaml["name"],
    "metric": {
        "goal": config_yaml["metric"]["goal"],
        "name": config_yaml["metric"]["name"],
    },
    "parameters": {
        "batch_size": {"values": config_yaml["parameters"]["batch_size"]},
        "epochs": {"values": config_yaml["parameters"]["epochs"]},
        "lr": {
            "max": config_yaml["parameters"]["learning_rate"]["max"],
            "min": config_yaml["parameters"]["learning_rate"]["min"],
        },
    },
}

"""
"""
# Define sweep config
sweep_configuration = {
    "method": "random",
    "name": "sweep",
    "metric": {"goal": "maximize", "name": "val_acc"},
    "parameters": {
        "batch_size": {"values": [16, 32, 64]},
        "epochs": {"values": [5, 10, 15]},
        "lr": {"max": 0.1, "min": 0.0001},
    },
}
"""

# Initialize sweep by passing in config. (Optional) Provide a name of the project.
sweep_id = wandb.sweep(sweep=sweep_configuration, project="my-first-sweep")

# Define training function that takes in hyperparameter values from `wandb.config` and uses them to train a model and return metric
def train_one_epoch(epoch, lr, bs):
    acc = 0.25 + ((epoch / 30) + (random.random() / 10))
    loss = 0.2 + (1 - ((epoch - 1) / 10 + random.random() / 5))
    return acc, loss


def evaluate_one_epoch(epoch):
    acc = 0.1 + ((epoch / 20) + (random.random() / 10))
    loss = 0.25 + (1 - ((epoch - 1) / 10 + random.random() / 6))
    return acc, loss


def main():
    run = wandb.init()

    # note that we define values from `wandb.config` instead
    # of defining hard values
    lr = wandb.config.lr
    bs = wandb.config.batch_size
    epochs = wandb.config.epochs

    for epoch in np.arange(1, epochs):
        train_acc, train_loss = train_one_epoch(epoch, lr, bs)
        val_acc, val_loss = evaluate_one_epoch(epoch)

        wandb.log(
            {
                "epoch": epoch,
                "train_acc": train_acc,
                "train_loss": train_loss,
                "val_acc": val_acc,
                "val_loss": val_loss,
            }
        )


# Start sweep job.
wandb.agent(sweep_id, function=main, count=4)
